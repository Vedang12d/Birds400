{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\ntrain_dir = \"../input/100-bird-species/train\"\nvalid_dir = \"../input/100-bird-species/valid\"\ntest_dir = \"../input/100-bird-species/test\"\nclasses = os.listdir(train_dir)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T01:17:53.430812Z","iopub.execute_input":"2022-08-18T01:17:53.431262Z","iopub.status.idle":"2022-08-18T01:17:53.437909Z","shell.execute_reply.started":"2022-08-18T01:17:53.431226Z","shell.execute_reply":"2022-08-18T01:17:53.436869Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1)\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir, target_size=(224, 224), batch_size=32, class_mode=\"categorical\"\n)\n\nval_datagen = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1)\nval_generator = val_datagen.flow_from_directory(\n    valid_dir, target_size=(224, 224), batch_size=32, class_mode=\"categorical\"\n)\n\ntest_datagen = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1)\ntest_generator = test_datagen.flow_from_directory(\n    test_dir, target_size=(224, 224), batch_size=32, class_mode=\"categorical\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T01:17:54.682343Z","iopub.execute_input":"2022-08-18T01:17:54.682726Z","iopub.status.idle":"2022-08-18T01:17:58.640756Z","shell.execute_reply.started":"2022-08-18T01:17:54.682695Z","shell.execute_reply":"2022-08-18T01:17:58.639695Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Found 58388 images belonging to 400 classes.\nFound 2000 images belonging to 400 classes.\nFound 2000 images belonging to 400 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow\nbase_model = tensorflow.keras.applications.efficientnet.EfficientNetB4(\n    include_top=False, weights='imagenet', input_shape=(224, 224, 3), pooling='max'\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T01:17:58.642885Z","iopub.execute_input":"2022-08-18T01:17:58.643289Z","iopub.status.idle":"2022-08-18T01:18:01.648118Z","shell.execute_reply.started":"2022-08-18T01:17:58.643250Z","shell.execute_reply":"2022-08-18T01:18:01.647132Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization, Flatten\nfrom tensorflow.keras import regularizers\nmodel=Sequential()\nmodel.add(base_model)\nmodel.add(BatchNormalization())\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(0.45))\nmodel.add(Dense(400, activation=\"softmax\"))","metadata":{"execution":{"iopub.status.busy":"2022-08-18T01:18:03.603033Z","iopub.execute_input":"2022-08-18T01:18:03.603772Z","iopub.status.idle":"2022-08-18T01:18:05.162208Z","shell.execute_reply.started":"2022-08-18T01:18:03.603736Z","shell.execute_reply":"2022-08-18T01:18:05.161266Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-18T01:18:05.863020Z","iopub.execute_input":"2022-08-18T01:18:05.863653Z","iopub.status.idle":"2022-08-18T01:18:05.892422Z","shell.execute_reply.started":"2022-08-18T01:18:05.863613Z","shell.execute_reply":"2022-08-18T01:18:05.891332Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nefficientnetb4 (Functional)  (None, 1792)              17673823  \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 1792)              7168      \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               918016    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 400)               205200    \n=================================================================\nTotal params: 18,804,207\nTrainable params: 18,675,416\nNon-trainable params: 128,791\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport time\nclass LRA(tf.keras.callbacks.Callback):\n    def __init__(self,model, base_model, patience,stop_patience, threshold, factor, dwell, batches, initial_epoch,epochs, ask_epoch, csv_path=None):\n        super(LRA, self).__init__()\n        self.model=model\n        self.base_model=base_model\n        self.patience=patience # specifies how many epochs without improvement before learning rate is adjusted\n        self.stop_patience=stop_patience # specifies how many times to adjust lr without improvement to stop training\n        self.threshold=threshold # specifies training accuracy threshold when lr will be adjusted based on validation loss\n        self.factor=factor # factor by which to reduce the learning rate\n        self.dwell=dwell\n        self.batches=batches # number of training batch to runn per epoch\n        self.initial_epoch=initial_epoch\n        self.epochs=epochs\n        self.ask_epoch=ask_epoch\n        self.ask_epoch_initial=ask_epoch # save this value to restore if restarting training\n        # self.csv_path=csv_path\n        # callback variables \n        self.count=0 # how many times lr has been reduced without improvement\n        self.stop_count=0        \n        self.best_epoch=1   # epoch with the lowest loss        \n        self.initial_lr=float(tf.keras.optimizers.Adam().lr.numpy()) # get the initiallearning rate and save it         \n        self.highest_tracc=0.0 # set highest training accuracy to 0 initially\n        self.lowest_vloss=np.inf # set lowest validation loss to infinity initially\n        self.best_weights=self.model.get_weights() # set best weights to model's initial weights\n        self.initial_weights=self.model.get_weights()   # save initial weights if they have to get restored \n        self.data_dict={}\n        for key in ['epoch','tr loss','tr acc','vloss','vacc','current lr','next lr','monitor','% improv','duration']:\n            self.data_dict[key]=[]\n    def on_train_begin(self, logs=None):        \n        if self.base_model != None:\n            status=base_model.trainable\n            if status:\n                msg=' initializing callback starting training with base_model trainable'\n            else:\n                msg='initializing callback starting training with base_model not trainable'\n        else:\n            msg='initialing callback and starting training'                        \n        print(msg) \n        msg='{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:10s}{9:^8s}'.format('Epoch', 'Loss', 'Accuracy', 'V_loss','V_acc', 'LR', 'Next LR', 'Monitor','% Improv', 'Duration')\n        print(msg) \n        self.start_time= time.time()\n        \n    def on_train_end(self, logs=None):\n        stop_time=time.time()\n        tr_duration= stop_time- self.start_time            \n        hours = tr_duration // 3600\n        minutes = (tr_duration - (hours * 3600)) // 60\n        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n        # if self.csv_path !=None:\n        #     df=pd.DataFrame.from_dict(self.data_dict)\n        #     now = datetime.now() \n        #     year = str(now.year)\n        #     month=str(now.month)\n        #     day=str(now.day)\n        #     hour=str(now.hour)\n        #     minute=str(now.minute)\n        #     sec=str(now.second)\n        #     label = month + '-'+ day + '-' + year + '-' + hour + '-' + minute + '-' + sec +'.csv'\n        #     csv_path=self.csv_path + '-'+ label\n        #     df.to_csv(csv_path, index=False)\n        #     print('training data saved as ', csv_path)\n\n        self.model.set_weights(self.best_weights) # set the weights of the model to the best weights\n        msg=f'Training is completed - model is set with weights from epoch {self.best_epoch} '\n        print(msg)\n        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n        print(msg)   \n        \n    def on_train_batch_end(self, batch, logs=None):\n        acc=logs['accuracy']* 100  # get training accuracy \n        loss=logs.get('loss')\n        msg='{0:20s}processing batch {1:4s} of {2:5s} accuracy= {3:8.3f}  loss: {4:8.5f}'.format('', str(batch), str(self.batches), acc, loss)\n#         print(msg, end='\\r') # prints over on the same line to show running batch count        \n        \n    def on_epoch_begin(self,epoch, logs=None):\n        self.now= time.time()\n        \n    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n        later=time.time()\n        duration=later-self.now \n        lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n        current_lr=lr\n        v_loss=logs['val_loss']  # get the validation loss for this epoch\n        acc=logs['accuracy']  # get training accuracy \n        v_acc=logs['val_accuracy']\n        loss=logs['loss']        \n        if acc < self.threshold: # if training accuracy is below threshold adjust lr based on training accuracy\n            monitor='accuracy'\n            if epoch ==0:\n                pimprov=0.0\n            else:\n                pimprov= (acc-self.highest_tracc )*100/self.highest_tracc\n            if acc>self.highest_tracc: # training accuracy improved in the epoch                \n                self.highest_tracc=acc # set new highest training accuracy\n                self.best_weights=self.model.get_weights() # traing accuracy improved so save the weights\n                self.count=0 # set count to 0 since training accuracy improved\n                self.stop_count=0 # set stop counter to 0\n                if v_loss<self.lowest_vloss:\n                    self.lowest_vloss=v_loss\n                # color= (0,255,0)\n                self.best_epoch=epoch + 1  # set the value of best epoch for this epoch              \n            else: \n                # training accuracy did not improve check if this has happened for patience number of epochs\n                # if so adjust learning rate\n                if self.count>=self.patience -1: # lr should be adjusted\n                    # color=(245, 170, 66)\n                    lr*=self.factor # adjust the learning by factor\n                    tf.keras.backend.set_value(self.model.optimizer.lr, lr) # set the learning rate in the optimizer\n                    self.count=0 # reset the count to 0\n                    self.stop_count+=1 # count the number of consecutive lr adjustments\n                    self.count=0 # reset counter\n                    if self.dwell:\n                        self.model.set_weights(self.best_weights) # return to better point in N space                        \n                    elif v_loss<self.lowest_vloss:\n                        self.lowest_vloss=v_loss                                    \n                else:\n                    self.count+=1 # increment patience counter                    \n        else: # training accuracy is above threshold so adjust learning rate based on validation loss\n            monitor='val_loss'\n            if epoch==0:\n                pimprov=0.0\n            else:\n                pimprov= (self.lowest_vloss- v_loss )*100/self.lowest_vloss\n            if v_loss< self.lowest_vloss: # check if the validation loss improved \n                self.lowest_vloss=v_loss # replace lowest validation loss with new validation loss                \n                self.best_weights=self.model.get_weights() # validation loss improved so save the weights\n                self.count=0 # reset count since validation loss improved  \n                self.stop_count=0  \n                # color=(0,255,0)                \n                self.best_epoch=epoch + 1 # set the value of the best epoch to this epoch\n            else: # validation loss did not improve\n                if self.count>=self.patience-1: # need to adjust lr\n                    # color=(245, 170, 66)\n                    lr*=self.factor # adjust the learning rate                    \n                    self.stop_count+=1 # increment stop counter because lr was adjusted \n                    self.count=0 # reset counter\n                    tf.keras.backend.set_value(self.model.optimizer.lr, lr) # set the learning rate in the optimizer\n                    if self.dwell:\n                        self.model.set_weights(self.best_weights) # return to better point in N space\n                else: \n                    self.count+=1 # increment the patience counter                    \n                if acc>self.highest_tracc:\n                    self.highest_tracc= acc\n        msg=f'{str(epoch+1):^3s}/{str(self.epochs):4s} {loss:^9.3f}{acc*100:^9.3f}{v_loss:^9.5f}{v_acc*100:^9.3f}{current_lr:^9.5f}{lr:^9.5f}{monitor:^11s}{pimprov:^10.2f}{duration:^8.2f}'\n        print(msg)\n        key_list=['epoch','tr loss','tr acc','vloss','vacc','current lr','next lr','monitor','% improv','duration']\n        val_list =[epoch + 1, loss, acc, v_loss, v_acc, current_lr, lr, monitor, pimprov, duration]\n        for key, value in zip(key_list, val_list):\n           self.data_dict[key].append(value)\n        \n        if self.stop_count> self.stop_patience - 1: # check if learning rate has been adjusted stop_count times with no improvement\n            msg=f' training has been halted at epoch {epoch + 1} after {self.stop_patience} adjustments of learning rate with no improvement'\n            print(msg)\n            self.model.stop_training = True # stop training\n        else: \n            if self.ask_epoch !=None:\n                if epoch + 1 >= self.ask_epoch:\n                    if base_model.trainable:\n                        msg='enter H to halt training or an integer for number of epochs to run then ask again'\n                    else:\n                        msg='enter H to halt training ,F to fine tune model, or an integer for number of epochs to run then ask again'\n                    print(msg)\n                    ans=input('')                    \n                    if ans=='H' or ans=='h':\n                        msg=f'training has been halted at epoch {epoch + 1} due to user input'\n                        print(msg)\n                        self.model.stop_training = True # stop training\n                    elif ans == 'T' or ans=='t':\n                        if base_model.trainable:\n                            msg='base_model is already set as trainable'\n                        else:\n                            msg='setting base_model as trainable for fine tuning of model'\n                            self.base_model.trainable=True\n                        print(msg)\n                        msg='Enter an integer for the number of epochs to run then be asked again'\n                        print(msg)\n                        ans=int(input())\n                        self.ask_epoch +=ans\n                        msg=f' training will continue until epoch ' + str(self.ask_epoch) \n                        print(msg)    \n                        msg='{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:^8s}'.format('Epoch', 'Loss', 'Accuracy', 'V_loss','V_acc', 'LR', 'Next LR', 'Monitor','% Improv', 'Duration')\n                        print(msg)                         \n                        self.count=0\n                        self.stop_count=0                        \n                        self.ask_epoch = epoch + 1 + self.ask_epoch_initial \n                        \n                    else:\n                        ans=int(ans)\n                        self.ask_epoch +=ans\n                        msg=f' training will continue until epoch ' + str(self.ask_epoch)                         \n                        print(msg)\n                        msg='{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^10s}{8:10s}{9:^8s}'.format('Epoch', 'Loss', 'Accuracy', 'V_loss','V_acc', 'LR', 'Next LR', 'Monitor','% Improv', 'Duration')\n                        print(msg) ","metadata":{"execution":{"iopub.status.busy":"2022-08-18T01:18:07.532143Z","iopub.execute_input":"2022-08-18T01:18:07.532501Z","iopub.status.idle":"2022-08-18T01:18:07.568667Z","shell.execute_reply.started":"2022-08-18T01:18:07.532469Z","shell.execute_reply":"2022-08-18T01:18:07.567552Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ntrain_steps=int(np.ceil(len(train_generator.labels)/32))","metadata":{"execution":{"iopub.status.busy":"2022-08-18T01:18:09.390113Z","iopub.execute_input":"2022-08-18T01:18:09.391633Z","iopub.status.idle":"2022-08-18T01:18:09.396518Z","shell.execute_reply.started":"2022-08-18T01:18:09.391590Z","shell.execute_reply":"2022-08-18T01:18:09.395511Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"patience= 1 # number of epochs to wait to adjust lr if monitored value does not improve\nstop_patience =3 # number of epochs to wait before stopping training if monitored value does not improve\nthreshold=.9 # if train accuracy is < threshhold adjust monitor accuracy, else monitor validation loss\nfactor=.5 # factor to reduce lr by\ndwell=True # experimental, if True and monitored metric does not improve on current epoch set  modelweights back to weights of previous epoch\nfreeze=False # if true free weights of  the base model\nask_epoch=20 # number of epochs to run before asking if you want to halt training\nbatches=train_steps\n# csv_path=os.path.join(working_dir,'my_csv')\ncallbacks=[LRA(model=model,base_model= base_model,patience=patience,stop_patience=stop_patience, threshold=threshold, factor=factor,dwell=dwell, batches=batches,initial_epoch=0,epochs=40, ask_epoch=ask_epoch)]","metadata":{"execution":{"iopub.status.busy":"2022-08-18T01:18:13.789498Z","iopub.execute_input":"2022-08-18T01:18:13.790592Z","iopub.status.idle":"2022-08-18T01:18:14.201897Z","shell.execute_reply.started":"2022-08-18T01:18:13.790549Z","shell.execute_reply":"2022-08-18T01:18:14.200395Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"],\n)\nhistory = model.fit(\n    train_generator, epochs=40, callbacks=callbacks, validation_data=val_generator, shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T01:18:18.480392Z","iopub.execute_input":"2022-08-18T01:18:18.481127Z","iopub.status.idle":"2022-08-18T07:57:17.568783Z","shell.execute_reply.started":"2022-08-18T01:18:18.481066Z","shell.execute_reply":"2022-08-18T07:57:17.567754Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":" initializing callback starting training with base_model trainable\n Epoch     Loss   Accuracy  V_loss    V_acc     LR     Next LR  Monitor  % Improv  Duration\nEpoch 1/40\n1825/1825 [==============================] - 1290s 697ms/step - loss: 2.0857 - accuracy: 0.5625 - val_loss: 0.4809 - val_accuracy: 0.8800\n 1 /40     2.086   56.246   0.48088  88.000   0.00100  0.00100  accuracy     0.00   1289.91 \nEpoch 2/40\n1825/1825 [==============================] - 1085s 594ms/step - loss: 0.9685 - accuracy: 0.7652 - val_loss: 0.3461 - val_accuracy: 0.9125\n 2 /40     0.969   76.519   0.34609  91.250   0.00100  0.00100  accuracy    36.04   1084.72 \nEpoch 3/40\n1825/1825 [==============================] - 1094s 599ms/step - loss: 0.8219 - accuracy: 0.8019 - val_loss: 0.3718 - val_accuracy: 0.8940\n 3 /40     0.822   80.188   0.37184  89.400   0.00100  0.00100  accuracy     4.79   1094.38 \nEpoch 4/40\n1825/1825 [==============================] - 1096s 600ms/step - loss: 0.7267 - accuracy: 0.8248 - val_loss: 0.2854 - val_accuracy: 0.9310\n 4 /40     0.727   82.479   0.28541  93.100   0.00100  0.00100  accuracy     2.86   1095.62 \nEpoch 5/40\n1825/1825 [==============================] - 1088s 596ms/step - loss: 0.6437 - accuracy: 0.8428 - val_loss: 0.2359 - val_accuracy: 0.9335\n 5 /40     0.644   84.279   0.23589  93.350   0.00100  0.00100  accuracy     2.18   1088.05 \nEpoch 6/40\n1825/1825 [==============================] - 1082s 593ms/step - loss: 0.5750 - accuracy: 0.8574 - val_loss: 0.2950 - val_accuracy: 0.9310\n 6 /40     0.575   85.735   0.29503  93.100   0.00100  0.00100  accuracy     1.73   1081.91 \nEpoch 7/40\n1825/1825 [==============================] - 1078s 590ms/step - loss: 0.5273 - accuracy: 0.8675 - val_loss: 0.2258 - val_accuracy: 0.9435\n 7 /40     0.527   86.746   0.22582  94.350   0.00100  0.00100  accuracy     1.18   1077.86 \nEpoch 8/40\n1825/1825 [==============================] - 1077s 590ms/step - loss: 0.4712 - accuracy: 0.8806 - val_loss: 0.1859 - val_accuracy: 0.9510\n 8 /40     0.471   88.059   0.18588  95.100   0.00100  0.00100  accuracy     1.51   1077.11 \nEpoch 9/40\n1825/1825 [==============================] - 1080s 591ms/step - loss: 0.4271 - accuracy: 0.8902 - val_loss: 0.1767 - val_accuracy: 0.9555\n 9 /40     0.427   89.020   0.17672  95.550   0.00100  0.00100  accuracy     1.09   1079.68 \nEpoch 10/40\n1825/1825 [==============================] - 1079s 591ms/step - loss: 0.3771 - accuracy: 0.9014 - val_loss: 0.1508 - val_accuracy: 0.9605\n10 /40     0.377   90.140   0.15084  96.050   0.00100  0.00100  val_loss    14.64   1078.59 \nEpoch 11/40\n1825/1825 [==============================] - 1074s 589ms/step - loss: 0.3527 - accuracy: 0.9062 - val_loss: 0.1622 - val_accuracy: 0.9625\n11 /40     0.353   90.618   0.16219  96.250   0.00100  0.00050  val_loss    -7.52   1074.46 \nEpoch 12/40\n1825/1825 [==============================] - 1077s 590ms/step - loss: 0.2027 - accuracy: 0.9438 - val_loss: 0.0930 - val_accuracy: 0.9775\n12 /40     0.203   94.376   0.09299  97.750   0.00050  0.00050  val_loss    38.36   1076.97 \nEpoch 13/40\n1825/1825 [==============================] - 1077s 590ms/step - loss: 0.1645 - accuracy: 0.9536 - val_loss: 0.0987 - val_accuracy: 0.9760\n13 /40     0.164   95.359   0.09867  97.600   0.00050  0.00025  val_loss    -6.11   1077.39 \nEpoch 14/40\n1825/1825 [==============================] - 1077s 590ms/step - loss: 0.1220 - accuracy: 0.9642 - val_loss: 0.0701 - val_accuracy: 0.9825\n14 /40     0.122   96.417   0.07008  98.250   0.00025  0.00025  val_loss    24.63   1076.54 \nEpoch 15/40\n1825/1825 [==============================] - 1079s 591ms/step - loss: 0.0909 - accuracy: 0.9723 - val_loss: 0.0777 - val_accuracy: 0.9840\n15 /40     0.091   97.234   0.07774  98.400   0.00025  0.00013  val_loss    -10.92  1078.65 \nEpoch 16/40\n1825/1825 [==============================] - 1074s 588ms/step - loss: 0.0808 - accuracy: 0.9758 - val_loss: 0.0716 - val_accuracy: 0.9855\n16 /40     0.081   97.580   0.07160  98.550   0.00013  0.00006  val_loss    -2.16   1073.96 \nEpoch 17/40\n1825/1825 [==============================] - 1068s 585ms/step - loss: 0.0774 - accuracy: 0.9764 - val_loss: 0.0667 - val_accuracy: 0.9860\n17 /40     0.077   97.640   0.06671  98.600   0.00006  0.00006  val_loss     4.81   1067.54 \nEpoch 18/40\n1825/1825 [==============================] - 1069s 585ms/step - loss: 0.0635 - accuracy: 0.9802 - val_loss: 0.0649 - val_accuracy: 0.9860\n18 /40     0.063   98.024   0.06492  98.600   0.00006  0.00006  val_loss     2.69   1068.58 \nEpoch 19/40\n1825/1825 [==============================] - 1065s 584ms/step - loss: 0.0552 - accuracy: 0.9824 - val_loss: 0.0590 - val_accuracy: 0.9860\n19 /40     0.055   98.243   0.05900  98.600   0.00006  0.00006  val_loss     9.12   1065.44 \nEpoch 20/40\n1825/1825 [==============================] - 1069s 586ms/step - loss: 0.0506 - accuracy: 0.9838 - val_loss: 0.0686 - val_accuracy: 0.9865\n20 /40     0.051   98.376   0.06857  98.650   0.00006  0.00003  val_loss    -16.23  1069.01 \nenter H to halt training or an integer for number of epochs to run then ask again\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" 5\n"},{"name":"stdout","text":" training will continue until epoch 25\n Epoch     Loss   Accuracy  V_loss    V_acc     LR     Next LR  Monitor  % Improv  Duration\nEpoch 21/40\n1825/1825 [==============================] - 1080s 591ms/step - loss: 0.0497 - accuracy: 0.9846 - val_loss: 0.0635 - val_accuracy: 0.9875\n21 /40     0.050   98.457   0.06354  98.750   0.00003  0.00002  val_loss    -7.71   1079.74 \nEpoch 22/40\n1825/1825 [==============================] - 1071s 587ms/step - loss: 0.0506 - accuracy: 0.9840 - val_loss: 0.0591 - val_accuracy: 0.9895\n22 /40     0.051   98.397   0.05915  98.950   0.00002  0.00001  val_loss    -0.26   1070.86 \n training has been halted at epoch 22 after 3 adjustments of learning rate with no improvement\nTraining is completed - model is set with weights from epoch 19 \ntraining elapsed time was 6.0 hours, 38.0 minutes, 58.33 seconds)\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(history.history[\"loss\"], label=\"loss\")\nplt.plot(history.history[\"val_loss\"], label=\"val_loss\")\nplt.legend()\nplt.show()\n\nplt.plot(history.history[\"accuracy\"], label=\"acc\")\nplt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-18T07:58:05.058597Z","iopub.execute_input":"2022-08-18T07:58:05.058979Z","iopub.status.idle":"2022-08-18T07:58:48.563872Z","shell.execute_reply.started":"2022-08-18T07:58:05.058949Z","shell.execute_reply":"2022-08-18T07:58:48.562984Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"model.evaluate(test_generator)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-18T07:59:01.402652Z","iopub.execute_input":"2022-08-18T07:59:01.403315Z","iopub.status.idle":"2022-08-18T07:59:36.588498Z","shell.execute_reply.started":"2022-08-18T07:59:01.403274Z","shell.execute_reply":"2022-08-18T07:59:36.587577Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"63/63 [==============================] - 35s 549ms/step - loss: 0.0284 - accuracy: 0.9940\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"[0.028397297486662865, 0.9940000176429749]"},"metadata":{}}]}]}